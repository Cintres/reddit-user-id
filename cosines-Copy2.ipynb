{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, ArrayType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, HashingTF, StandardScaler, Normalizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import pandas as pd\n",
    "from nltk.util import skipgrams\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    ps.sql.SparkSession.builder\n",
    "    .master(\"local[4]\")\n",
    "    .appName(\"project1\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"42_users.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.groupby('author').agg(F.count('body'))\n",
    "authors = new_df.filter(new_df['count(body)']>500).select('author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              author|                body|\n",
      "+--------------------+--------------------+\n",
      "|dntletmygfknowimhere|                   A|\n",
      "|dntletmygfknowimhere|I sold him for Co...|\n",
      "|dntletmygfknowimhere|That same way, bu...|\n",
      "|dntletmygfknowimhere|          Everyone..|\n",
      "|dntletmygfknowimhere|                   A|\n",
      "|dntletmygfknowimhere|I personally like...|\n",
      "|dntletmygfknowimhere|Why did you hold ...|\n",
      "|dntletmygfknowimhere|Everything is eit...|\n",
      "|dntletmygfknowimhere|You don’t ride do...|\n",
      "|dntletmygfknowimhere|Quickie. \n",
      "\n",
      "Russel...|\n",
      "|dntletmygfknowimhere|             Goodbye|\n",
      "|dntletmygfknowimhere|Username doesn’t ...|\n",
      "|dntletmygfknowimhere|          Maybe 299%|\n",
      "|dntletmygfknowimhere|That’s true. My t...|\n",
      "|dntletmygfknowimhere|Breaking new: chi...|\n",
      "|dntletmygfknowimhere|That’s what I’ve ...|\n",
      "|dntletmygfknowimhere|                   V|\n",
      "|dntletmygfknowimhere|There’s little on...|\n",
      "|dntletmygfknowimhere|                   @|\n",
      "|dntletmygfknowimhere|             ����‍♂️|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df = authors.join(df, ['author'], 'left')\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = filtered_df.randomSplit([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|              author|count(body)|\n",
      "+--------------------+-----------+\n",
      "|dntletmygfknowimhere|        328|\n",
      "|            darkhorn|        517|\n",
      "|         truballa030|        580|\n",
      "|     melissastandard|        313|\n",
      "|              Yaglis|       1482|\n",
      "|           Macklebro|       1309|\n",
      "|         DuckyDawg55|        725|\n",
      "|          killnik420|        807|\n",
      "|NoYeezyInYourSerrano|        377|\n",
      "|          Colin03129|        377|\n",
      "|              nowake|        979|\n",
      "| shelbyamonkeysuncle|        554|\n",
      "|     jl_theprofessor|       2671|\n",
      "|   myKidsLike2Scream|        633|\n",
      "|             a_frayn|        996|\n",
      "|         stuntman628|        304|\n",
      "|   DankDungeonDelver|        564|\n",
      "|       QuoteMasterLT|       1571|\n",
      "|     alreadypiecrust|       1452|\n",
      "|     TheOddScientist|       1550|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupby('author').agg(F.count('body')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|              author|count(body)|\n",
      "+--------------------+-----------+\n",
      "|dntletmygfknowimhere|        310|\n",
      "|            darkhorn|        528|\n",
      "|         truballa030|        547|\n",
      "|     melissastandard|        282|\n",
      "|              Yaglis|       1510|\n",
      "|           Macklebro|       1343|\n",
      "|         DuckyDawg55|        739|\n",
      "|          killnik420|        814|\n",
      "|NoYeezyInYourSerrano|        354|\n",
      "|          Colin03129|        379|\n",
      "|              nowake|        989|\n",
      "| shelbyamonkeysuncle|        569|\n",
      "|     jl_theprofessor|       2673|\n",
      "|   myKidsLike2Scream|        635|\n",
      "|             a_frayn|       1089|\n",
      "|         stuntman628|        298|\n",
      "|   DankDungeonDelver|        554|\n",
      "|       QuoteMasterLT|       1554|\n",
      "|     alreadypiecrust|       1474|\n",
      "|     TheOddScientist|       1545|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby('author').agg(F.count('body')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments1 = df1.groupBy(\"author\").agg(F.collect_list(\"body\"))\n",
    "join_comments_udf = udf(lambda x: ' '.join(x), StringType())\n",
    "df1_join_comments = comments1.withColumn('corpus', join_comments_udf(comments1['collect_list(body)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|              author|  collect_list(body)|              corpus|link_count|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|dntletmygfknowimhere|[ Got the same on...| Got the same one...|         1|\n",
      "|            darkhorn|[\"Because you dow...|\"Because you down...|         1|\n",
      "|         truballa030|[\"Drew\" Bledsoe, ...|\"Drew\" Bledsoe \"T...|         0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_links(s):\n",
    "    try:\n",
    "        num_links = len(re.findall(r'\\(http.+\\)', s)[0].split(')('))\n",
    "        return num_links\n",
    "    except:\n",
    "        return 0\n",
    "count_links_udf = udf(count_links, IntegerType())\n",
    "df_count_links1 = df1_join_comments.withColumn(\n",
    "    'link_count', count_links_udf(df1_join_comments['corpus']))\n",
    "df_count_links1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_links(s):\n",
    "    return re.sub(r'\\(http.+\\)', '', s)\n",
    "drop_links_udf = udf(drop_links, StringType())\n",
    "df_drop_links1 = df_count_links1.withColumn('corpus', drop_links_udf(df_count_links1['corpus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|              author|  collect_list(body)|              corpus|link_count|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|dntletmygfknowimhere|[ Got the same on...| Got the same one...|         1|\n",
      "|            darkhorn|[\"Because you dow...|\"Because you down...|         1|\n",
      "|         truballa030|[\"Drew\" Bledsoe, ...|\"Drew\" Bledsoe \"T...|         0|\n",
      "|     melissastandard|[8+ hours of sun ...|8+ hours of sun  ...|         0|\n",
      "|              Yaglis|[\"*Come at me bro...|\"*Come at me bro!...|         1|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_drop_links1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    s = s.lower()\n",
    "    token = TweetTokenizer()\n",
    "    return token.tokenize(s)\n",
    "\n",
    "tokenize_udf = udf(tokenize, ArrayType(StringType()))\n",
    "df_tokens1 = df_drop_links1.withColumn('tokens', tokenize_udf(df_drop_links1['corpus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(s):\n",
    "    return [i for i in s if i.isalpha()]\n",
    "        \n",
    "find_words_udf = udf(find_words, ArrayType(StringType()))\n",
    "df_find_words1 = df_tokens1.withColumn('words', find_words_udf(df_tokens1['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_length(words):\n",
    "    return [len(word) for word in words]\n",
    "\n",
    "word_length_udf = udf(word_length, ArrayType(IntegerType()))\n",
    "word_length_df1 = df_find_words1.withColumn('word_lengths', word_length_udf(df_find_words1['words']))\n",
    "total_words_udf = udf(lambda x: len(x), IntegerType())\n",
    "total_words_df1 = word_length_df1.withColumn('total_words', total_words_udf(word_length_df1['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagger(s):\n",
    "    return [i[1] for i in nltk.pos_tag(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger_udf = udf(pos_tagger, ArrayType(StringType()))\n",
    "df_pos_tagger1 = total_words_df1.withColumn('POS', pos_tagger_udf(total_words_df1['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "|              author|  collect_list(body)|              corpus|link_count|              tokens|               words|        word_lengths|total_words|                 POS|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "|dntletmygfknowimhere|[ Got the same on...| Got the same one...|         1|[got, the, same, ...|[got, the, same, ...|[3, 3, 4, 3, 9, 2...|       6937|[VBD, DT, JJ, NN,...|\n",
      "|            darkhorn|[\"Because you dow...|\"Because you down...|         1|[\", because, you,...|[because, you, do...|[7, 3, 6, 2, 5, 3...|      10897|[NN, IN, PRP, VBD...|\n",
      "|         truballa030|[\"Drew\" Bledsoe, ...|\"Drew\" Bledsoe \"T...|         0|[\", drew, \", bled...|[drew, bledsoe, t...|[4, 7, 5, 4, 5, 7...|       8342|[NN, VBD, JJ, NN,...|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pos_tagger1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_grams(s):\n",
    "    grams = []\n",
    "    for i in skipgrams(s,2,2):\n",
    "        grams.append(str(i))\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams_udf = udf(skip_grams, ArrayType(StringType()))\n",
    "df_skip_grams1 = df_pos_tagger1.withColumn('skip_grams', skip_grams_udf(df_pos_tagger1['POS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('skip_grams.csv', 'r') as f:\n",
    "  reader = csv.reader(f)\n",
    "  com_skips = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('NN', 'NN')\",\n",
       " \"('DT', 'NN')\",\n",
       " \"('JJ', 'NN')\",\n",
       " \"('IN', 'NN')\",\n",
       " \"('NN', 'IN')\",\n",
       " \"('NN', '.')\",\n",
       " \"('IN', 'DT')\",\n",
       " \"('NN', 'JJ')\",\n",
       " \"('NN', 'DT')\",\n",
       " \"('.', 'NN')\",\n",
       " \"('NN', 'RB')\",\n",
       " \"('DT', 'JJ')\",\n",
       " \"('NN', ',')\",\n",
       " \"('IN', 'JJ')\",\n",
       " \"('VB', 'NN')\",\n",
       " \"('DT', 'IN')\",\n",
       " \"('JJ', 'IN')\",\n",
       " \"('NN', 'PRP')\",\n",
       " \"('NN', 'CC')\",\n",
       " \"('NN', 'VB')\",\n",
       " \"('NN', 'VBZ')\",\n",
       " \"('JJ', '.')\",\n",
       " \"('RB', 'NN')\",\n",
       " \"('NN', 'VBD')\",\n",
       " \"('NN', 'NNS')\",\n",
       " \"('.', 'JJ')\",\n",
       " \"('RB', 'JJ')\",\n",
       " \"('RB', 'IN')\",\n",
       " \"('IN', 'IN')\",\n",
       " \"('JJ', 'JJ')\",\n",
       " \"('JJ', 'NNS')\",\n",
       " \"('TO', 'VB')\",\n",
       " \"('VB', 'DT')\",\n",
       " \"('NN', 'VBP')\",\n",
       " \"('IN', '.')\",\n",
       " \"('VB', 'IN')\",\n",
       " \"('IN', 'NNS')\",\n",
       " \"('IN', 'PRP')\",\n",
       " \"('NNS', 'IN')\",\n",
       " \"('DT', '.')\",\n",
       " \"('.', 'DT')\",\n",
       " \"('.', 'RB')\",\n",
       " \"('NNS', 'NN')\",\n",
       " \"('VBP', 'NN')\",\n",
       " \"('RB', 'DT')\",\n",
       " \"('CC', 'NN')\",\n",
       " \"(',', 'NN')\",\n",
       " \"('PRP$', 'NN')\",\n",
       " \"('.', 'IN')\",\n",
       " \"('VB', 'JJ')\",\n",
       " \"('PRP', 'VBP')\",\n",
       " \"('PRP', 'VB')\",\n",
       " \"('DT', 'NNS')\",\n",
       " \"('.', 'VB')\",\n",
       " \"('RB', 'RB')\",\n",
       " \"('JJ', 'DT')\",\n",
       " \"('.', 'PRP')\",\n",
       " \"('RB', '.')\",\n",
       " \"('VBD', 'NN')\",\n",
       " \"('MD', 'VB')\",\n",
       " \"('NNS', 'VBP')\",\n",
       " \"('PRP', 'IN')\",\n",
       " \"('RB', 'VB')\",\n",
       " \"('VBZ', 'NN')\",\n",
       " \"('JJ', 'RB')\",\n",
       " \"('NN', 'TO')\",\n",
       " \"('NN', 'VBG')\",\n",
       " \"('NNS', '.')\",\n",
       " \"('VBP', 'IN')\",\n",
       " \"('VBP', 'JJ')\",\n",
       " \"('VBG', 'NN')\",\n",
       " \"('VBP', 'DT')\",\n",
       " \"('PRP', 'RB')\",\n",
       " \"('PRP', 'DT')\",\n",
       " \"('PRP', 'NN')\",\n",
       " \"('IN', 'RB')\",\n",
       " \"('JJ', 'VBP')\",\n",
       " \"('DT', 'DT')\",\n",
       " \"('.', 'VBP')\",\n",
       " \"('VBZ', 'JJ')\",\n",
       " \"('VB', 'PRP')\",\n",
       " \"('JJ', ',')\",\n",
       " \"('VBZ', 'DT')\",\n",
       " \"('PRP', 'JJ')\",\n",
       " \"(',', 'RB')\",\n",
       " \"('JJ', 'CC')\",\n",
       " \"('VBD', 'DT')\",\n",
       " \"('VBD', 'IN')\",\n",
       " \"('DT', 'RB')\",\n",
       " \"('VB', '.')\",\n",
       " \"('NNS', 'RB')\",\n",
       " \"('NNS', 'DT')\",\n",
       " \"('IN', ',')\",\n",
       " \"('VB', 'RB')\",\n",
       " \"('NNS', 'JJ')\",\n",
       " \"('PRP', '.')\",\n",
       " \"('RB', 'PRP')\",\n",
       " \"('TO', 'NN')\",\n",
       " \"('CC', 'JJ')\",\n",
       " \"('IN', 'VBP')\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skips = com_skips[0]\n",
    "skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_grams_filter(s):\n",
    "    return [i for i in s if i in skips]\n",
    "com_skips_udf = udf(skip_grams_filter, ArrayType(StringType()))\n",
    "df_com_skips1 = df_skip_grams1.withColumn('com_skips', com_skips_udf(df_skip_grams1['skip_grams']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "x = [i.split(\"'\")for i in stops]\n",
    "stops = [i[0] for i in x]\n",
    "stops = list(set(stops))\n",
    "slang_stops = ['gonna', 'coulda', 'shoulda',\n",
    "               'lotta', 'lots', 'oughta', 'gotta', 'ain', 'sorta', 'kinda', 'yeah', 'whatever', 'cuz', 'ya', 'haha', 'lol', 'eh']\n",
    "puncts = ['!', ':', '...', '.', '%', '$', \"'\", '\"', ';']\n",
    "formattings = ['##', '__', '_', '    ', '*', '**']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(slang_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(formattings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_filter(s):\n",
    "    return [i for i in s if i in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_udf = udf(stop_words_filter, ArrayType(StringType()))\n",
    "df_stop_words1 = df_com_skips1.withColumn('stop_words', stop_words_udf(df_com_skips1['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(type):\n",
    "    def concat_(*args):\n",
    "        return list(chain.from_iterable((arg if arg else [] for arg in args)))\n",
    "    return udf(concat_, ArrayType(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_arrays_udf = concat(StringType())\n",
    "df_all_words1 = df_stop_words1.select(\"author\", concat_arrays_udf(\"stop_words\", \"com_skips\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(numFeatures=285, inputCol='concat_(stop_words, com_skips)', outputCol='features')\n",
    "tf1 = hashingTF.transform(df_all_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_norm1 = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1).transform(tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler(inputCol='features_norm', outputCol='scaled', withMean=True)\n",
    "scale_fit1 = stdscaler.fit(tf_norm1)\n",
    "scaled1 = scale_fit1.transform(tf_norm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments2 = df2.groupBy(\"author\").agg(F.collect_list(\"body\"))\n",
    "join_comments_udf = udf(lambda x: ' '.join(x), StringType())\n",
    "df2_join_comments = comments2.withColumn('corpus', join_comments_udf(comments2['collect_list(body)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_links2 = df2_join_comments.withColumn(\n",
    "    'link_count', count_links_udf(df2_join_comments['corpus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_links2 = df_count_links2.withColumn('corpus', drop_links_udf(df_count_links2['corpus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens2 = df_drop_links2.withColumn('tokens', tokenize_udf(df_drop_links2['corpus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger_udf = udf(pos_tagger, ArrayType(StringType()))\n",
    "df_pos_tagger2 = df_tokens2.withColumn('POS', pos_tagger_udf(df_tokens2['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams_udf = udf(skip_grams, ArrayType(StringType()))\n",
    "df_skip_grams2 = df_pos_tagger2.withColumn('skip_grams', skip_grams_udf(df_pos_tagger2['POS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_skips_udf = udf(skip_grams_filter, ArrayType(StringType()))\n",
    "df_com_skips2 = df_skip_grams2.withColumn('com_skips', com_skips_udf(df_skip_grams2['skip_grams']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop_words2 = df_com_skips2.withColumn('stop_words', stop_words_udf(df_com_skips2['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_words2 = df_stop_words2.select(\"author\", concat_arrays_udf(\"stop_words\", \"com_skips\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2 = hashingTF.transform(df_all_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_norm2 = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1).transform(tf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled2 = scale_fit1.transform(tf_norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims1 = scaled1.select('author','scaled')\n",
    "sims2 = scaled2.select('author','scaled')\n",
    "similarities = {}\n",
    "for i in sims1.rdd.collect():\n",
    "    similarity = {}\n",
    "    auth1, vec1 = i[0], i[1]\n",
    "    for j in sims2.rdd.collect():\n",
    "        auth2, vec2 = j[0], j[1]\n",
    "        cos = vec1.dot(vec2) / (vec2.norm(2)*vec1.norm(2))\n",
    "        similarity [auth2] = cos\n",
    "    similarities [auth1] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pdf.columns\n",
    "mask = []\n",
    "for i in pdf:\n",
    "    mask.append(i == pdf.index)\n",
    "mask = np.array(mask)\n",
    "mask = mask.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pdf.values[mask]\n",
    "non_matches = pdf.values[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_mas = non_matches.reshape(27,-1)\n",
    "non_mas_max = np.max(non_mas, axis=1)\n",
    "np.sum(matches > non_mas_max) / len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(matches , label='matches')\n",
    "plt.hist(non_matches, label='non-matches')\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.legend()\n",
    "plt.savefig('match_distro.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 5., 7., 3., 1., 5.]),\n",
       " array([0.147423  , 0.20715399, 0.26688498, 0.32661596, 0.38634695,\n",
       "        0.44607793, 0.50580892, 0.5655399 , 0.62527089]),\n",
       " <a list of 8 Patch objects>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(matches - non_mas_max, bins=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matches.csv', 'a') as f:\n",
    "    wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(matches)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nonmatches.csv', 'a') as f:\n",
    "    wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(non_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCCC1 = total_words_df1.select('author', 'word_lengths', 'total_words')\n",
    "# word_freqs1 = {}\n",
    "# for i in MCCC1.rdd.collect():\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for k, v in (dict(nltk.FreqDist(i[1]))).items():\n",
    "#         x.append(k)\n",
    "#         y.append(v / i[2])\n",
    "#     idx = np.argsort(x)[1:12]\n",
    "#     z = np.array(y)[idx]\n",
    "#     plt.plot(range(1,12), z)\n",
    "#     word_freqs1[i[0]] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_freqs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_links(s):\n",
    "    try:\n",
    "        num_links = len(re.findall(r'\\(http.+\\)', s)[0].split(')('))\n",
    "        return num_links\n",
    "    except:\n",
    "        return 0\n",
    "count_links_udf = udf(count_links, IntegerType())\n",
    "df_count_links2 = df2_join_comments.withColumn(\n",
    "    'link_count', count_links_udf(df2_join_comments['corpus']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_links(s):\n",
    "    return re.sub(r'\\(http.+\\)', '', s)\n",
    "drop_links_udf = udf(drop_links, StringType())\n",
    "df_drop_links2 = df_count_links2.withColumn('corpus', drop_links_udf(df_count_links2['corpus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    s = s.lower()\n",
    "    token = TweetTokenizer()\n",
    "    return token.tokenize(s)\n",
    "\n",
    "tokenize_udf = udf(tokenize, ArrayType(StringType()))\n",
    "df_tokens2 = df_drop_links2.withColumn('tokens', tokenize_udf(df_drop_links2['corpus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(s):\n",
    "    return [i for i in s if i.isalpha()]\n",
    "        \n",
    "find_words_udf = udf(find_words, ArrayType(StringType()))\n",
    "df_find_words2 = df_tokens2.withColumn('words', find_words_udf(df_tokens2['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_length(words):\n",
    "    return [len(word) for word in words]\n",
    "\n",
    "word_length_udf = udf(word_length, ArrayType(IntegerType()))\n",
    "word_length_df2 = df_find_words2.withColumn('word_lengths', word_length_udf(df_find_words2['words']))\n",
    "total_words_udf = udf(lambda x: len(x), IntegerType())\n",
    "total_words_df2 = word_length_df2.withColumn('total_words', total_words_udf(word_length_df2['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+\n",
      "|              author|  collect_list(body)|              corpus|link_count|              tokens|               words|        word_lengths|total_words|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+\n",
      "|dntletmygfknowimhere|[11-13 targets a ...|11-13 targets a g...|         1|[11-13, targets, ...|[targets, a, game...|[7, 1, 4, 12, 2, ...|       7108|\n",
      "|           Ashaman21|[\"Not talking abo...|\"Not talking abou...|         0|[\", not, talking,...|[not, talking, ab...|[3, 7, 5, 3, 12, ...|       3400|\n",
      "|            darkhorn|[\"Because you dow...|\"Because you down...|         1|[\", because, you,...|[because, you, do...|[7, 3, 6, 2, 5, 3...|      11842|\n",
      "|         truballa030|[&gt; Darrelle Re...|&gt; Darrelle Rev...|         1|[>, darrelle, rev...|[darrelle, revis,...|[8, 5, 3, 6, 5, 3...|       8945|\n",
      "|     melissastandard|[ Very!!!!, A guy...| Very!!!! A guy w...|         0|[very, !, !, !, a...|[very, a, guy, wo...|[4, 1, 3, 7, 2, 3...|       6640|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_words_df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCCC2 = total_words_df2.select('author', 'word_lengths', 'total_words')\n",
    "# word_freqs2 = {}\n",
    "# for i in MCCC2.rdd.collect():\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for k, v in (dict(nltk.FreqDist(i[1]))).items():\n",
    "#         x.append(k)\n",
    "#         y.append(v / i[2])\n",
    "#     idx = np.argsort(x)[1:12]\n",
    "#     z = np.array(y)[idx]\n",
    "#     plt.plot(range(1,12), z)\n",
    "#     word_freqs2[i[0]] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_freqs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #find RMSE for each of the users\n",
    "# word_lengths = {}\n",
    "# for key, value in word_freqs1.items():\n",
    "#     error_values = {}\n",
    "#     for k, v in word_freqs2.items():\n",
    "#         rmse = np.mean(np.sqrt((v-value)**2))\n",
    "#         error_values[k] = rmse\n",
    "#     word_lengths[key] = error_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(word_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = df.plot(kind='bar', figsize=(16,8), title='RMSE of User Word Length Choices')\n",
    "# fig = ax.get_figure()\n",
    "# fig.savefig('word_length_errors.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2,1,figsize=(10,12))\n",
    "# for key, value in word_freqs1.items():\n",
    "#     ax[0].plot(range(1,12), value, label=key)\n",
    "# ax[0].set_ylabel('% of Total Words')\n",
    "# ax[0].set_xlabel('Word Length')\n",
    "# ax[0].set_title('Word Choice Frequencies: Subset 1')\n",
    "# ax[0].legend()\n",
    "# for key, value in word_freqs2.items():\n",
    "#     ax[1].plot(range(1,12), value, label=key)\n",
    "# ax[1].set_ylabel('% of Total Words')\n",
    "# ax[1].set_xlabel('Word Length')\n",
    "# ax[1].set_title('Word Choice Frequencies: Subset 2')\n",
    "# ax[1].legend()\n",
    "# fig.savefig('word_lengths.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "x = [i.split(\"'\")for i in stops]\n",
    "stops = [i[0] for i in x]\n",
    "stops = list(set(stops))\n",
    "slang_stops = ['gonna', 'coulda', 'shoulda',\n",
    "               'lotta', 'lots', 'oughta', 'gotta', 'ain', 'sorta', 'kinda', 'yeah', 'whatever', 'cuz', 'ya', 'haha', 'lol', 'eh']\n",
    "puncts = ['!', ':', '...', '.', '%', '$', \"'\", '\"', ';']\n",
    "formattings = ['##', '__', '_', '    ', '*', '**']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(slang_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(formattings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_filter(s):\n",
    "    return [i for i in s if i in stops]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_udf = udf(stop_words_filter, ArrayType(StringType()))\n",
    "df_stop_words1 = total_words_df1.withColumn('stop_words', stop_words_udf(total_words_df1['tokens']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(numFeatures=179, inputCol='stop_words', outputCol='features')\n",
    "tf1 = hashingTF.transform(df_stop_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_norm1 = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1).transform(tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler(inputCol='features_norm', outputCol='scaled', withMean=True)\n",
    "scale_fit1 = stdscaler.fit(tf_norm1)\n",
    "scaled1 = scale_fit1.transform(tf_norm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|              author|  collect_list(body)|              corpus|link_count|              tokens|               words|        word_lengths|total_words|          stop_words|            features|       features_norm|              scaled|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|dntletmygfknowimhere|[1-2, 10/11/15, 1...|1-2 10/11/15 11-1...|         1|[1-2, 10/11, /, 1...|[targets, a, game...|[7, 1, 4, 12, 2, ...|       7234|[a, is, ., i, wha...|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[-0.1861533446362...|\n",
      "|           Ashaman21|[\"Not talking abo...|\"Not talking abou...|         0|[\", not, talking,...|[not, talking, ab...|[3, 7, 5, 3, 12, ...|       3603|[\", not, about, h...|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[0.75099036323358...|\n",
      "|            darkhorn|[    &lt;?php\n",
      "   ...|    &lt;?php\n",
      "    ...|         1|[<, ?, php, $, a,...|[php, a, movies, ...|[3, 1, 6, 5, 1, 6...|      11346|[$, a, ', ', $, a...|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[-0.7672199526912...|\n",
      "|         truballa030|[\"Grab dat shit J...|\"Grab dat shit Jo...|         1|[\", grab, dat, sh...|[grab, dat, shit,...|[4, 3, 4, 2, 8, 5...|       8659|[\", \", was, for, ...|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[1.40512211170489...|\n",
      "|     melissastandard|[A primitive plat...|A primitive plate...|         0|[a, primitive, pl...|[a, primitive, pl...|[1, 9, 5, 4, 9, 2...|       7182|[a, ., to, the, ....|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[-0.2355311924916...|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_udf = udf(stop_words_filter, ArrayType(StringType()))\n",
    "df_stop_words2 = total_words_df2.withColumn('stop_words', stop_words_udf(total_words_df2['tokens']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(numFeatures=179, inputCol='stop_words', outputCol='features')\n",
    "tf2 = hashingTF.transform(df_stop_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_norm2 = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1).transform(tf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler(inputCol='features_norm', outputCol='scaled', withMean=True)\n",
    "scale_fit2 = stdscaler.fit(tf_norm2)\n",
    "scaled2 = scale_fit2.transform(tf_norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|              author|  collect_list(body)|              corpus|link_count|              tokens|               words|        word_lengths|total_words|          stop_words|            features|       features_norm|              scaled|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|dntletmygfknowimhere|[/, 1 karma. 9 ye...|/ 1 karma. 9 year...|         1|[/, 1, karma, ., ...|[karma, years, da...|[5, 5, 4, 1, 6, 1...|       6720|[., ., a, all, th...|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[0.05805348912460...|\n",
      "|           Ashaman21|[$10?  Aren't the...|$10?  Aren't they...|         0|[$, 10, ?, aren't...|[they, like, item...|[4, 4, 5, 3, 4, 4...|       3069|[$, they, now, .,...|(179,[0,5,7,9,13,...|(179,[0,5,7,9,13,...|[1.11223406652558...|\n",
      "|            darkhorn|[\"Tunisia has dem...|\"Tunisia has demo...|         1|[\", tunisia, has,...|[tunisia, has, de...|[7, 3, 9, 3, 5, 3...|      11338|[\", has, now, \", ...|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[-1.2520765494628...|\n",
      "|         truballa030|[&gt; Darrelle Re...|&gt; Darrelle Rev...|         0|[>, darrelle, rev...|[darrelle, revis,...|[8, 5, 3, 6, 5, 3...|       9233|[was, for, $, ., ...|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[-0.1604527998853...|\n",
      "|     melissastandard|[ Very!!!!, \"Ther...| Very!!!! \"There ...|         0|[very, !, !, !, \"...|[very, there, is,...|[4, 5, 2, 2, 4, 4...|       6425|[very, !, !, !, \"...|(179,[0,5,7,8,9,1...|(179,[0,5,7,8,9,1...|[-0.3587514174148...|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims1 = scaled1.select('author','scaled')\n",
    "sims2 = scaled2.select('author','scaled')\n",
    "similarities = {}\n",
    "for i in sims1.rdd.collect():\n",
    "    similarity = {}\n",
    "    auth1, vec1 = i[0], i[1]\n",
    "    for j in sims2.rdd.collect():\n",
    "        auth2, vec2 = j[0], j[1]\n",
    "        cos = vec1.dot(vec2) / (vec2.norm(2)*vec1.norm(2))\n",
    "        similarity [auth2] = cos\n",
    "    similarities [auth1] = similarity\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pdf.columns\n",
    "mask = []\n",
    "for i in pdf:\n",
    "    mask.append(i == pdf.index)\n",
    "mask = np.array(mask)\n",
    "mask = mask.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dntletmygfknowimhere</th>\n",
       "      <th>Ashaman21</th>\n",
       "      <th>darkhorn</th>\n",
       "      <th>truballa030</th>\n",
       "      <th>melissastandard</th>\n",
       "      <th>Yaglis</th>\n",
       "      <th>Macklebro</th>\n",
       "      <th>DuckyDawg55</th>\n",
       "      <th>killnik420</th>\n",
       "      <th>NoYeezyInYourSerrano</th>\n",
       "      <th>...</th>\n",
       "      <th>glackbuy99</th>\n",
       "      <th>AevnNoram</th>\n",
       "      <th>wahmeiman1975</th>\n",
       "      <th>Flashy_Gardener</th>\n",
       "      <th>Gay_Black_Atheist</th>\n",
       "      <th>kawow02</th>\n",
       "      <th>dvaldez0919</th>\n",
       "      <th>cocorazor</th>\n",
       "      <th>jessetmia</th>\n",
       "      <th>Jimmy2e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AevnNoram</th>\n",
       "      <td>-0.097932</td>\n",
       "      <td>-0.038870</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.149221</td>\n",
       "      <td>-0.149164</td>\n",
       "      <td>0.063680</td>\n",
       "      <td>0.027135</td>\n",
       "      <td>-0.102060</td>\n",
       "      <td>-0.235987</td>\n",
       "      <td>-0.145421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121178</td>\n",
       "      <td>0.695392</td>\n",
       "      <td>-0.015190</td>\n",
       "      <td>-0.079269</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>-0.100473</td>\n",
       "      <td>-0.147875</td>\n",
       "      <td>-0.109408</td>\n",
       "      <td>-0.093517</td>\n",
       "      <td>0.020842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ashaman21</th>\n",
       "      <td>-0.165408</td>\n",
       "      <td>0.246578</td>\n",
       "      <td>-0.068616</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>-0.031076</td>\n",
       "      <td>-0.081990</td>\n",
       "      <td>0.021910</td>\n",
       "      <td>-0.148600</td>\n",
       "      <td>0.207720</td>\n",
       "      <td>0.039399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067171</td>\n",
       "      <td>-0.174363</td>\n",
       "      <td>0.121517</td>\n",
       "      <td>-0.070957</td>\n",
       "      <td>0.163876</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.129620</td>\n",
       "      <td>0.032462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colin03129</th>\n",
       "      <td>-0.207165</td>\n",
       "      <td>0.088088</td>\n",
       "      <td>-0.025910</td>\n",
       "      <td>-0.138920</td>\n",
       "      <td>-0.104438</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>-0.261085</td>\n",
       "      <td>-0.252467</td>\n",
       "      <td>-0.036224</td>\n",
       "      <td>0.068391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022279</td>\n",
       "      <td>-0.125436</td>\n",
       "      <td>0.114725</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>-0.059132</td>\n",
       "      <td>0.308662</td>\n",
       "      <td>-0.071668</td>\n",
       "      <td>-0.110783</td>\n",
       "      <td>0.084536</td>\n",
       "      <td>0.384408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DankDungeonDelver</th>\n",
       "      <td>-0.122641</td>\n",
       "      <td>-0.114316</td>\n",
       "      <td>-0.141943</td>\n",
       "      <td>-0.056200</td>\n",
       "      <td>-0.022564</td>\n",
       "      <td>0.245262</td>\n",
       "      <td>-0.264842</td>\n",
       "      <td>-0.101335</td>\n",
       "      <td>0.032233</td>\n",
       "      <td>-0.224168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010482</td>\n",
       "      <td>0.029036</td>\n",
       "      <td>-0.111219</td>\n",
       "      <td>0.145534</td>\n",
       "      <td>-0.050935</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>-0.121626</td>\n",
       "      <td>0.049232</td>\n",
       "      <td>0.258758</td>\n",
       "      <td>-0.009962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DuckyDawg55</th>\n",
       "      <td>0.260492</td>\n",
       "      <td>-0.156622</td>\n",
       "      <td>-0.073401</td>\n",
       "      <td>0.067935</td>\n",
       "      <td>0.154867</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.198523</td>\n",
       "      <td>0.653594</td>\n",
       "      <td>0.025110</td>\n",
       "      <td>-0.125271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.004239</td>\n",
       "      <td>-0.140664</td>\n",
       "      <td>-0.069674</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>-0.189279</td>\n",
       "      <td>0.138388</td>\n",
       "      <td>0.206339</td>\n",
       "      <td>-0.026809</td>\n",
       "      <td>-0.151351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmmettRapaportNBA</th>\n",
       "      <td>-0.204634</td>\n",
       "      <td>0.032419</td>\n",
       "      <td>0.216410</td>\n",
       "      <td>0.102948</td>\n",
       "      <td>-0.252053</td>\n",
       "      <td>0.138292</td>\n",
       "      <td>-0.036508</td>\n",
       "      <td>-0.159288</td>\n",
       "      <td>-0.263069</td>\n",
       "      <td>0.102228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.315398</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>0.212947</td>\n",
       "      <td>0.193072</td>\n",
       "      <td>-0.064351</td>\n",
       "      <td>-0.243341</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>0.145931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flashy_Gardener</th>\n",
       "      <td>-0.182525</td>\n",
       "      <td>-0.156859</td>\n",
       "      <td>-0.000881</td>\n",
       "      <td>-0.167916</td>\n",
       "      <td>0.172988</td>\n",
       "      <td>-0.007663</td>\n",
       "      <td>-0.210114</td>\n",
       "      <td>0.018969</td>\n",
       "      <td>0.074441</td>\n",
       "      <td>-0.216465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058770</td>\n",
       "      <td>0.056927</td>\n",
       "      <td>0.314691</td>\n",
       "      <td>0.882818</td>\n",
       "      <td>-0.153332</td>\n",
       "      <td>-0.009024</td>\n",
       "      <td>-0.035538</td>\n",
       "      <td>0.247204</td>\n",
       "      <td>0.139687</td>\n",
       "      <td>-0.014765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gay_Black_Atheist</th>\n",
       "      <td>-0.184597</td>\n",
       "      <td>0.220668</td>\n",
       "      <td>-0.078874</td>\n",
       "      <td>0.018929</td>\n",
       "      <td>-0.157241</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.095103</td>\n",
       "      <td>0.124301</td>\n",
       "      <td>-0.057723</td>\n",
       "      <td>0.171161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121293</td>\n",
       "      <td>0.130341</td>\n",
       "      <td>0.097593</td>\n",
       "      <td>-0.190223</td>\n",
       "      <td>0.673280</td>\n",
       "      <td>0.127645</td>\n",
       "      <td>-0.019016</td>\n",
       "      <td>-0.146930</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>-0.098373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GuiHarrison</th>\n",
       "      <td>-0.136393</td>\n",
       "      <td>-0.051547</td>\n",
       "      <td>-0.019046</td>\n",
       "      <td>0.037945</td>\n",
       "      <td>-0.034065</td>\n",
       "      <td>0.061313</td>\n",
       "      <td>-0.111662</td>\n",
       "      <td>-0.068740</td>\n",
       "      <td>0.243221</td>\n",
       "      <td>-0.061132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105808</td>\n",
       "      <td>0.066518</td>\n",
       "      <td>-0.185273</td>\n",
       "      <td>-0.050678</td>\n",
       "      <td>-0.004974</td>\n",
       "      <td>-0.035610</td>\n",
       "      <td>-0.231362</td>\n",
       "      <td>-0.010895</td>\n",
       "      <td>-0.017911</td>\n",
       "      <td>-0.053957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jimmy2e</th>\n",
       "      <td>-0.206137</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>0.184476</td>\n",
       "      <td>-0.235154</td>\n",
       "      <td>-0.140687</td>\n",
       "      <td>-0.013416</td>\n",
       "      <td>-0.277641</td>\n",
       "      <td>-0.234765</td>\n",
       "      <td>-0.084548</td>\n",
       "      <td>0.079485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127731</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.090390</td>\n",
       "      <td>-0.029601</td>\n",
       "      <td>-0.263151</td>\n",
       "      <td>0.127507</td>\n",
       "      <td>-0.221698</td>\n",
       "      <td>-0.026097</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>0.594095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macklebro</th>\n",
       "      <td>0.304938</td>\n",
       "      <td>0.037133</td>\n",
       "      <td>0.035322</td>\n",
       "      <td>0.119807</td>\n",
       "      <td>-0.055193</td>\n",
       "      <td>0.107351</td>\n",
       "      <td>0.926194</td>\n",
       "      <td>0.135035</td>\n",
       "      <td>-0.113734</td>\n",
       "      <td>-0.025997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086080</td>\n",
       "      <td>-0.141624</td>\n",
       "      <td>-0.044117</td>\n",
       "      <td>-0.194757</td>\n",
       "      <td>0.114629</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>0.271543</td>\n",
       "      <td>-0.037908</td>\n",
       "      <td>-0.278673</td>\n",
       "      <td>-0.208811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoYeezyInYourSerrano</th>\n",
       "      <td>0.097321</td>\n",
       "      <td>-0.018897</td>\n",
       "      <td>0.009844</td>\n",
       "      <td>-0.148627</td>\n",
       "      <td>-0.094309</td>\n",
       "      <td>-0.154431</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>-0.030385</td>\n",
       "      <td>-0.140875</td>\n",
       "      <td>0.700255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269141</td>\n",
       "      <td>-0.035682</td>\n",
       "      <td>-0.045300</td>\n",
       "      <td>-0.251411</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>0.165660</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>-0.377418</td>\n",
       "      <td>-0.081972</td>\n",
       "      <td>0.258674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuoteMasterLT</th>\n",
       "      <td>0.487194</td>\n",
       "      <td>-0.064816</td>\n",
       "      <td>-0.133831</td>\n",
       "      <td>-0.087095</td>\n",
       "      <td>0.344630</td>\n",
       "      <td>-0.256285</td>\n",
       "      <td>0.235122</td>\n",
       "      <td>0.354249</td>\n",
       "      <td>-0.082692</td>\n",
       "      <td>0.197166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053060</td>\n",
       "      <td>-0.172455</td>\n",
       "      <td>-0.245305</td>\n",
       "      <td>-0.157970</td>\n",
       "      <td>-0.077724</td>\n",
       "      <td>-0.074487</td>\n",
       "      <td>0.276626</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>-0.295402</td>\n",
       "      <td>-0.178466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TheOddScientist</th>\n",
       "      <td>-0.279295</td>\n",
       "      <td>0.054751</td>\n",
       "      <td>0.141514</td>\n",
       "      <td>-0.200308</td>\n",
       "      <td>-0.046345</td>\n",
       "      <td>-0.141792</td>\n",
       "      <td>-0.283724</td>\n",
       "      <td>-0.157205</td>\n",
       "      <td>0.100255</td>\n",
       "      <td>-0.080974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008235</td>\n",
       "      <td>0.255954</td>\n",
       "      <td>0.162383</td>\n",
       "      <td>0.279963</td>\n",
       "      <td>-0.078121</td>\n",
       "      <td>-0.187504</td>\n",
       "      <td>-0.070349</td>\n",
       "      <td>0.135806</td>\n",
       "      <td>0.132196</td>\n",
       "      <td>0.257111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yaglis</th>\n",
       "      <td>-0.153120</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.194642</td>\n",
       "      <td>-0.089587</td>\n",
       "      <td>-0.135895</td>\n",
       "      <td>0.820622</td>\n",
       "      <td>0.018156</td>\n",
       "      <td>-0.172609</td>\n",
       "      <td>-0.012227</td>\n",
       "      <td>-0.020510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017563</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>-0.130201</td>\n",
       "      <td>-0.117998</td>\n",
       "      <td>0.197414</td>\n",
       "      <td>0.170174</td>\n",
       "      <td>-0.081575</td>\n",
       "      <td>0.051243</td>\n",
       "      <td>-0.112815</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_frayn</th>\n",
       "      <td>-0.069476</td>\n",
       "      <td>-0.131234</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>-0.055419</td>\n",
       "      <td>0.060036</td>\n",
       "      <td>-0.182218</td>\n",
       "      <td>-0.263228</td>\n",
       "      <td>-0.040682</td>\n",
       "      <td>0.055001</td>\n",
       "      <td>-0.228811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033255</td>\n",
       "      <td>0.180035</td>\n",
       "      <td>0.124823</td>\n",
       "      <td>0.322245</td>\n",
       "      <td>-0.051787</td>\n",
       "      <td>-0.196968</td>\n",
       "      <td>-0.136615</td>\n",
       "      <td>0.162711</td>\n",
       "      <td>0.265456</td>\n",
       "      <td>-0.065834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alreadypiecrust</th>\n",
       "      <td>-0.274003</td>\n",
       "      <td>0.203413</td>\n",
       "      <td>0.132510</td>\n",
       "      <td>-0.044270</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>-0.038321</td>\n",
       "      <td>-0.132678</td>\n",
       "      <td>-0.093662</td>\n",
       "      <td>0.099406</td>\n",
       "      <td>-0.171300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039163</td>\n",
       "      <td>0.131350</td>\n",
       "      <td>-0.125048</td>\n",
       "      <td>0.153761</td>\n",
       "      <td>-0.140030</td>\n",
       "      <td>-0.133713</td>\n",
       "      <td>-0.230443</td>\n",
       "      <td>0.189331</td>\n",
       "      <td>-0.119407</td>\n",
       "      <td>0.015312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocorazor</th>\n",
       "      <td>-0.001639</td>\n",
       "      <td>-0.011432</td>\n",
       "      <td>-0.034919</td>\n",
       "      <td>-0.090712</td>\n",
       "      <td>0.127573</td>\n",
       "      <td>-0.004882</td>\n",
       "      <td>-0.048589</td>\n",
       "      <td>0.201295</td>\n",
       "      <td>0.264245</td>\n",
       "      <td>-0.247964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128899</td>\n",
       "      <td>-0.074666</td>\n",
       "      <td>-0.094271</td>\n",
       "      <td>0.267266</td>\n",
       "      <td>-0.124575</td>\n",
       "      <td>-0.127994</td>\n",
       "      <td>-0.141446</td>\n",
       "      <td>0.929678</td>\n",
       "      <td>-0.169047</td>\n",
       "      <td>-0.113545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrl-shft-esc</th>\n",
       "      <td>-0.024592</td>\n",
       "      <td>-0.021345</td>\n",
       "      <td>-0.089802</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>-0.102653</td>\n",
       "      <td>-0.080588</td>\n",
       "      <td>0.065203</td>\n",
       "      <td>-0.113258</td>\n",
       "      <td>0.131833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073867</td>\n",
       "      <td>0.128621</td>\n",
       "      <td>-0.187376</td>\n",
       "      <td>-0.059074</td>\n",
       "      <td>-0.046838</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>-0.091593</td>\n",
       "      <td>0.127053</td>\n",
       "      <td>-0.104845</td>\n",
       "      <td>-0.181873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>darkhorn</th>\n",
       "      <td>-0.218975</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.875532</td>\n",
       "      <td>-0.115267</td>\n",
       "      <td>-0.143867</td>\n",
       "      <td>0.150024</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>-0.200492</td>\n",
       "      <td>-0.149813</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152390</td>\n",
       "      <td>-0.034922</td>\n",
       "      <td>0.076691</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>0.144968</td>\n",
       "      <td>0.030359</td>\n",
       "      <td>-0.032091</td>\n",
       "      <td>-0.043569</td>\n",
       "      <td>-0.174443</td>\n",
       "      <td>0.198721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dntletmygfknowimhere</th>\n",
       "      <td>0.746387</td>\n",
       "      <td>-0.151070</td>\n",
       "      <td>-0.145028</td>\n",
       "      <td>-0.025887</td>\n",
       "      <td>0.113413</td>\n",
       "      <td>-0.159693</td>\n",
       "      <td>0.351181</td>\n",
       "      <td>0.371477</td>\n",
       "      <td>-0.117018</td>\n",
       "      <td>0.200928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>-0.132123</td>\n",
       "      <td>-0.139535</td>\n",
       "      <td>-0.127791</td>\n",
       "      <td>-0.163170</td>\n",
       "      <td>-0.179837</td>\n",
       "      <td>0.288102</td>\n",
       "      <td>0.025808</td>\n",
       "      <td>-0.182127</td>\n",
       "      <td>-0.253359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dvaldez0919</th>\n",
       "      <td>0.080805</td>\n",
       "      <td>0.124122</td>\n",
       "      <td>-0.011810</td>\n",
       "      <td>0.034544</td>\n",
       "      <td>0.091989</td>\n",
       "      <td>-0.050950</td>\n",
       "      <td>0.143443</td>\n",
       "      <td>0.030909</td>\n",
       "      <td>0.011387</td>\n",
       "      <td>-0.012898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009932</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.038820</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>-0.078047</td>\n",
       "      <td>-0.319448</td>\n",
       "      <td>0.408319</td>\n",
       "      <td>-0.056353</td>\n",
       "      <td>0.146944</td>\n",
       "      <td>-0.186908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glackbuy99</th>\n",
       "      <td>-0.198219</td>\n",
       "      <td>0.011144</td>\n",
       "      <td>0.079324</td>\n",
       "      <td>0.079035</td>\n",
       "      <td>-0.060229</td>\n",
       "      <td>-0.065963</td>\n",
       "      <td>-0.049945</td>\n",
       "      <td>-0.111242</td>\n",
       "      <td>0.130217</td>\n",
       "      <td>-0.162031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729558</td>\n",
       "      <td>-0.031905</td>\n",
       "      <td>0.035657</td>\n",
       "      <td>0.225458</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.021430</td>\n",
       "      <td>-0.046336</td>\n",
       "      <td>0.132697</td>\n",
       "      <td>-0.081239</td>\n",
       "      <td>-0.050172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iamnotkobe</th>\n",
       "      <td>-0.114888</td>\n",
       "      <td>-0.119357</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>0.175181</td>\n",
       "      <td>-0.102587</td>\n",
       "      <td>-0.019681</td>\n",
       "      <td>-0.155095</td>\n",
       "      <td>-0.156116</td>\n",
       "      <td>-0.122078</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074374</td>\n",
       "      <td>0.128434</td>\n",
       "      <td>0.121621</td>\n",
       "      <td>-0.117408</td>\n",
       "      <td>0.075923</td>\n",
       "      <td>0.049937</td>\n",
       "      <td>-0.015333</td>\n",
       "      <td>-0.206761</td>\n",
       "      <td>0.019344</td>\n",
       "      <td>-0.047522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jessetmia</th>\n",
       "      <td>-0.111592</td>\n",
       "      <td>-0.119014</td>\n",
       "      <td>-0.082036</td>\n",
       "      <td>-0.138440</td>\n",
       "      <td>0.023348</td>\n",
       "      <td>-0.160050</td>\n",
       "      <td>-0.286222</td>\n",
       "      <td>0.035589</td>\n",
       "      <td>-0.032400</td>\n",
       "      <td>-0.071126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052440</td>\n",
       "      <td>-0.055401</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>0.088114</td>\n",
       "      <td>0.031725</td>\n",
       "      <td>-0.003489</td>\n",
       "      <td>-0.045015</td>\n",
       "      <td>-0.198497</td>\n",
       "      <td>0.690508</td>\n",
       "      <td>0.150497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jl_theprofessor</th>\n",
       "      <td>-0.217831</td>\n",
       "      <td>-0.231932</td>\n",
       "      <td>-0.090275</td>\n",
       "      <td>-0.150710</td>\n",
       "      <td>-0.062716</td>\n",
       "      <td>-0.205017</td>\n",
       "      <td>-0.416388</td>\n",
       "      <td>-0.159075</td>\n",
       "      <td>0.057460</td>\n",
       "      <td>-0.042503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051552</td>\n",
       "      <td>0.258640</td>\n",
       "      <td>0.064370</td>\n",
       "      <td>0.098959</td>\n",
       "      <td>-0.177422</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>-0.290785</td>\n",
       "      <td>-0.141340</td>\n",
       "      <td>0.224897</td>\n",
       "      <td>0.297260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jlawler</th>\n",
       "      <td>-0.172207</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>-0.056684</td>\n",
       "      <td>-0.200688</td>\n",
       "      <td>-0.132370</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>-0.093507</td>\n",
       "      <td>-0.185547</td>\n",
       "      <td>0.218810</td>\n",
       "      <td>-0.141652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035685</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.079672</td>\n",
       "      <td>-0.121877</td>\n",
       "      <td>-0.062153</td>\n",
       "      <td>0.042536</td>\n",
       "      <td>-0.112986</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.094596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kawow02</th>\n",
       "      <td>-0.148396</td>\n",
       "      <td>0.082039</td>\n",
       "      <td>0.198604</td>\n",
       "      <td>0.035409</td>\n",
       "      <td>-0.113384</td>\n",
       "      <td>0.080034</td>\n",
       "      <td>-0.019352</td>\n",
       "      <td>-0.132999</td>\n",
       "      <td>-0.193383</td>\n",
       "      <td>0.162424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077242</td>\n",
       "      <td>-0.243455</td>\n",
       "      <td>-0.106422</td>\n",
       "      <td>-0.182656</td>\n",
       "      <td>0.137997</td>\n",
       "      <td>0.484714</td>\n",
       "      <td>-0.096204</td>\n",
       "      <td>-0.208113</td>\n",
       "      <td>-0.100974</td>\n",
       "      <td>0.243820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killnik420</th>\n",
       "      <td>-0.022282</td>\n",
       "      <td>0.213018</td>\n",
       "      <td>-0.103817</td>\n",
       "      <td>-0.076355</td>\n",
       "      <td>-0.007440</td>\n",
       "      <td>-0.067898</td>\n",
       "      <td>-0.098620</td>\n",
       "      <td>0.100780</td>\n",
       "      <td>0.756032</td>\n",
       "      <td>-0.193047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050804</td>\n",
       "      <td>-0.171420</td>\n",
       "      <td>0.066287</td>\n",
       "      <td>0.157928</td>\n",
       "      <td>-0.296101</td>\n",
       "      <td>-0.270563</td>\n",
       "      <td>-0.013725</td>\n",
       "      <td>0.349071</td>\n",
       "      <td>0.113506</td>\n",
       "      <td>-0.008599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melissastandard</th>\n",
       "      <td>0.153681</td>\n",
       "      <td>-0.208886</td>\n",
       "      <td>-0.195364</td>\n",
       "      <td>0.069299</td>\n",
       "      <td>0.526253</td>\n",
       "      <td>-0.001568</td>\n",
       "      <td>-0.054477</td>\n",
       "      <td>0.305741</td>\n",
       "      <td>-0.040500</td>\n",
       "      <td>-0.121763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010509</td>\n",
       "      <td>0.012672</td>\n",
       "      <td>-0.134081</td>\n",
       "      <td>0.176694</td>\n",
       "      <td>-0.144185</td>\n",
       "      <td>-0.205156</td>\n",
       "      <td>0.088444</td>\n",
       "      <td>0.145595</td>\n",
       "      <td>-0.193471</td>\n",
       "      <td>-0.241437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momomeomo</th>\n",
       "      <td>-0.060321</td>\n",
       "      <td>-0.054217</td>\n",
       "      <td>-0.039580</td>\n",
       "      <td>0.099138</td>\n",
       "      <td>0.061296</td>\n",
       "      <td>0.224411</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>-0.156435</td>\n",
       "      <td>-0.090280</td>\n",
       "      <td>-0.010445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128589</td>\n",
       "      <td>-0.058027</td>\n",
       "      <td>-0.210535</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>-0.113650</td>\n",
       "      <td>0.031039</td>\n",
       "      <td>-0.154052</td>\n",
       "      <td>-0.070656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myKidsLike2Scream</th>\n",
       "      <td>0.617367</td>\n",
       "      <td>-0.139749</td>\n",
       "      <td>-0.129494</td>\n",
       "      <td>-0.057920</td>\n",
       "      <td>0.187881</td>\n",
       "      <td>-0.192916</td>\n",
       "      <td>0.342550</td>\n",
       "      <td>0.331572</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.053068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081328</td>\n",
       "      <td>-0.139310</td>\n",
       "      <td>-0.153102</td>\n",
       "      <td>-0.128235</td>\n",
       "      <td>-0.034137</td>\n",
       "      <td>-0.126741</td>\n",
       "      <td>0.216293</td>\n",
       "      <td>0.089858</td>\n",
       "      <td>-0.155167</td>\n",
       "      <td>-0.235659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nankerjphelge</th>\n",
       "      <td>-0.181415</td>\n",
       "      <td>0.101907</td>\n",
       "      <td>0.113294</td>\n",
       "      <td>-0.046445</td>\n",
       "      <td>-0.232821</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>-0.145496</td>\n",
       "      <td>-0.273925</td>\n",
       "      <td>-0.043649</td>\n",
       "      <td>0.014998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091833</td>\n",
       "      <td>-0.024409</td>\n",
       "      <td>-0.051255</td>\n",
       "      <td>-0.131542</td>\n",
       "      <td>-0.083429</td>\n",
       "      <td>0.280201</td>\n",
       "      <td>-0.361619</td>\n",
       "      <td>-0.072495</td>\n",
       "      <td>-0.155376</td>\n",
       "      <td>0.332087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nowake</th>\n",
       "      <td>-0.215968</td>\n",
       "      <td>0.030681</td>\n",
       "      <td>-0.155257</td>\n",
       "      <td>-0.046859</td>\n",
       "      <td>-0.164002</td>\n",
       "      <td>0.037379</td>\n",
       "      <td>-0.257787</td>\n",
       "      <td>-0.213901</td>\n",
       "      <td>-0.020927</td>\n",
       "      <td>-0.026746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223722</td>\n",
       "      <td>0.332059</td>\n",
       "      <td>0.081698</td>\n",
       "      <td>-0.014706</td>\n",
       "      <td>0.074051</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>-0.109253</td>\n",
       "      <td>-0.159097</td>\n",
       "      <td>0.323395</td>\n",
       "      <td>0.305168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rxvf</th>\n",
       "      <td>-0.126456</td>\n",
       "      <td>0.161421</td>\n",
       "      <td>-0.043766</td>\n",
       "      <td>0.083260</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>-0.045580</td>\n",
       "      <td>0.043311</td>\n",
       "      <td>0.205412</td>\n",
       "      <td>-0.033282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>-0.020297</td>\n",
       "      <td>-0.163396</td>\n",
       "      <td>-0.023521</td>\n",
       "      <td>-0.072948</td>\n",
       "      <td>0.065204</td>\n",
       "      <td>-0.079752</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>-0.039305</td>\n",
       "      <td>-0.043001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schpork</th>\n",
       "      <td>-0.133116</td>\n",
       "      <td>0.030545</td>\n",
       "      <td>0.135453</td>\n",
       "      <td>-0.045321</td>\n",
       "      <td>-0.174374</td>\n",
       "      <td>0.225523</td>\n",
       "      <td>0.038420</td>\n",
       "      <td>-0.221665</td>\n",
       "      <td>-0.314490</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084265</td>\n",
       "      <td>0.014050</td>\n",
       "      <td>0.292551</td>\n",
       "      <td>0.117048</td>\n",
       "      <td>0.135327</td>\n",
       "      <td>0.384155</td>\n",
       "      <td>-0.014700</td>\n",
       "      <td>-0.340663</td>\n",
       "      <td>0.077938</td>\n",
       "      <td>0.135477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelbyamonkeysuncle</th>\n",
       "      <td>0.453652</td>\n",
       "      <td>-0.169306</td>\n",
       "      <td>-0.111109</td>\n",
       "      <td>0.008877</td>\n",
       "      <td>0.284123</td>\n",
       "      <td>-0.021010</td>\n",
       "      <td>0.202933</td>\n",
       "      <td>0.071585</td>\n",
       "      <td>-0.126287</td>\n",
       "      <td>-0.057307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074570</td>\n",
       "      <td>-0.120388</td>\n",
       "      <td>-0.262329</td>\n",
       "      <td>-0.104864</td>\n",
       "      <td>-0.083788</td>\n",
       "      <td>-0.074173</td>\n",
       "      <td>0.126785</td>\n",
       "      <td>0.166051</td>\n",
       "      <td>-0.255116</td>\n",
       "      <td>-0.211261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stuntman628</th>\n",
       "      <td>-0.141106</td>\n",
       "      <td>0.181041</td>\n",
       "      <td>-0.145851</td>\n",
       "      <td>0.058106</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.157453</td>\n",
       "      <td>-0.134214</td>\n",
       "      <td>-0.172822</td>\n",
       "      <td>0.031818</td>\n",
       "      <td>0.019503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002295</td>\n",
       "      <td>0.016155</td>\n",
       "      <td>0.035013</td>\n",
       "      <td>0.072333</td>\n",
       "      <td>-0.055356</td>\n",
       "      <td>-0.172221</td>\n",
       "      <td>0.035153</td>\n",
       "      <td>-0.111129</td>\n",
       "      <td>0.036916</td>\n",
       "      <td>-0.058539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporallock</th>\n",
       "      <td>0.079658</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>-0.160275</td>\n",
       "      <td>0.019252</td>\n",
       "      <td>0.014734</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.104839</td>\n",
       "      <td>-0.007403</td>\n",
       "      <td>0.227603</td>\n",
       "      <td>-0.049385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036115</td>\n",
       "      <td>-0.013848</td>\n",
       "      <td>-0.103905</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>-0.132981</td>\n",
       "      <td>-0.059080</td>\n",
       "      <td>-0.076430</td>\n",
       "      <td>-0.054260</td>\n",
       "      <td>0.124882</td>\n",
       "      <td>-0.054173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truballa030</th>\n",
       "      <td>-0.049517</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>-0.219306</td>\n",
       "      <td>0.650006</td>\n",
       "      <td>-0.079236</td>\n",
       "      <td>-0.139037</td>\n",
       "      <td>-0.021488</td>\n",
       "      <td>-0.018523</td>\n",
       "      <td>-0.036392</td>\n",
       "      <td>-0.136352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075229</td>\n",
       "      <td>0.045389</td>\n",
       "      <td>-0.032224</td>\n",
       "      <td>-0.238744</td>\n",
       "      <td>0.090999</td>\n",
       "      <td>-0.032677</td>\n",
       "      <td>0.049403</td>\n",
       "      <td>-0.180130</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>-0.259369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wahmeiman1975</th>\n",
       "      <td>-0.075452</td>\n",
       "      <td>-0.038079</td>\n",
       "      <td>0.064952</td>\n",
       "      <td>-0.171105</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>-0.027247</td>\n",
       "      <td>-0.012707</td>\n",
       "      <td>-0.179553</td>\n",
       "      <td>0.041747</td>\n",
       "      <td>-0.125105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086699</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>0.741068</td>\n",
       "      <td>0.255066</td>\n",
       "      <td>0.077713</td>\n",
       "      <td>-0.101227</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>-0.006540</td>\n",
       "      <td>0.272525</td>\n",
       "      <td>0.094750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dntletmygfknowimhere  Ashaman21  darkhorn  truballa030  \\\n",
       "AevnNoram                        -0.097932  -0.038870  0.001416     0.149221   \n",
       "Ashaman21                        -0.165408   0.246578 -0.068616     0.034913   \n",
       "Colin03129                       -0.207165   0.088088 -0.025910    -0.138920   \n",
       "DankDungeonDelver                -0.122641  -0.114316 -0.141943    -0.056200   \n",
       "DuckyDawg55                       0.260492  -0.156622 -0.073401     0.067935   \n",
       "EmmettRapaportNBA                -0.204634   0.032419  0.216410     0.102948   \n",
       "Flashy_Gardener                  -0.182525  -0.156859 -0.000881    -0.167916   \n",
       "Gay_Black_Atheist                -0.184597   0.220668 -0.078874     0.018929   \n",
       "GuiHarrison                      -0.136393  -0.051547 -0.019046     0.037945   \n",
       "Jimmy2e                          -0.206137   0.155319  0.184476    -0.235154   \n",
       "Macklebro                         0.304938   0.037133  0.035322     0.119807   \n",
       "NoYeezyInYourSerrano              0.097321  -0.018897  0.009844    -0.148627   \n",
       "QuoteMasterLT                     0.487194  -0.064816 -0.133831    -0.087095   \n",
       "TheOddScientist                  -0.279295   0.054751  0.141514    -0.200308   \n",
       "Yaglis                           -0.153120   0.010123  0.194642    -0.089587   \n",
       "a_frayn                          -0.069476  -0.131234  0.003811    -0.055419   \n",
       "alreadypiecrust                  -0.274003   0.203413  0.132510    -0.044270   \n",
       "cocorazor                        -0.001639  -0.011432 -0.034919    -0.090712   \n",
       "ctrl-shft-esc                    -0.024592  -0.021345 -0.089802     0.031562   \n",
       "darkhorn                         -0.218975   0.011709  0.875532    -0.115267   \n",
       "dntletmygfknowimhere              0.746387  -0.151070 -0.145028    -0.025887   \n",
       "dvaldez0919                       0.080805   0.124122 -0.011810     0.034544   \n",
       "glackbuy99                       -0.198219   0.011144  0.079324     0.079035   \n",
       "iamnotkobe                       -0.114888  -0.119357  0.047709     0.175181   \n",
       "jessetmia                        -0.111592  -0.119014 -0.082036    -0.138440   \n",
       "jl_theprofessor                  -0.217831  -0.231932 -0.090275    -0.150710   \n",
       "jlawler                          -0.172207   0.033216 -0.056684    -0.200688   \n",
       "kawow02                          -0.148396   0.082039  0.198604     0.035409   \n",
       "killnik420                       -0.022282   0.213018 -0.103817    -0.076355   \n",
       "melissastandard                   0.153681  -0.208886 -0.195364     0.069299   \n",
       "momomeomo                        -0.060321  -0.054217 -0.039580     0.099138   \n",
       "myKidsLike2Scream                 0.617367  -0.139749 -0.129494    -0.057920   \n",
       "nankerjphelge                    -0.181415   0.101907  0.113294    -0.046445   \n",
       "nowake                           -0.215968   0.030681 -0.155257    -0.046859   \n",
       "rxvf                             -0.126456   0.161421 -0.043766     0.083260   \n",
       "schpork                          -0.133116   0.030545  0.135453    -0.045321   \n",
       "shelbyamonkeysuncle               0.453652  -0.169306 -0.111109     0.008877   \n",
       "stuntman628                      -0.141106   0.181041 -0.145851     0.058106   \n",
       "temporallock                      0.079658   0.014812 -0.160275     0.019252   \n",
       "truballa030                      -0.049517   0.056427 -0.219306     0.650006   \n",
       "wahmeiman1975                    -0.075452  -0.038079  0.064952    -0.171105   \n",
       "\n",
       "                      melissastandard    Yaglis  Macklebro  DuckyDawg55  \\\n",
       "AevnNoram                   -0.149164  0.063680   0.027135    -0.102060   \n",
       "Ashaman21                   -0.031076 -0.081990   0.021910    -0.148600   \n",
       "Colin03129                  -0.104438  0.150664  -0.261085    -0.252467   \n",
       "DankDungeonDelver           -0.022564  0.245262  -0.264842    -0.101335   \n",
       "DuckyDawg55                  0.154867  0.010648   0.198523     0.653594   \n",
       "EmmettRapaportNBA           -0.252053  0.138292  -0.036508    -0.159288   \n",
       "Flashy_Gardener              0.172988 -0.007663  -0.210114     0.018969   \n",
       "Gay_Black_Atheist           -0.157241  0.012497   0.095103     0.124301   \n",
       "GuiHarrison                 -0.034065  0.061313  -0.111662    -0.068740   \n",
       "Jimmy2e                     -0.140687 -0.013416  -0.277641    -0.234765   \n",
       "Macklebro                   -0.055193  0.107351   0.926194     0.135035   \n",
       "NoYeezyInYourSerrano        -0.094309 -0.154431   0.039363    -0.030385   \n",
       "QuoteMasterLT                0.344630 -0.256285   0.235122     0.354249   \n",
       "TheOddScientist             -0.046345 -0.141792  -0.283724    -0.157205   \n",
       "Yaglis                      -0.135895  0.820622   0.018156    -0.172609   \n",
       "a_frayn                      0.060036 -0.182218  -0.263228    -0.040682   \n",
       "alreadypiecrust              0.114000 -0.038321  -0.132678    -0.093662   \n",
       "cocorazor                    0.127573 -0.004882  -0.048589     0.201295   \n",
       "ctrl-shft-esc                0.001445 -0.102653  -0.080588     0.065203   \n",
       "darkhorn                    -0.143867  0.150024   0.018418    -0.200492   \n",
       "dntletmygfknowimhere         0.113413 -0.159693   0.351181     0.371477   \n",
       "dvaldez0919                  0.091989 -0.050950   0.143443     0.030909   \n",
       "glackbuy99                  -0.060229 -0.065963  -0.049945    -0.111242   \n",
       "iamnotkobe                  -0.102587 -0.019681  -0.155095    -0.156116   \n",
       "jessetmia                    0.023348 -0.160050  -0.286222     0.035589   \n",
       "jl_theprofessor             -0.062716 -0.205017  -0.416388    -0.159075   \n",
       "jlawler                     -0.132370  0.024384  -0.093507    -0.185547   \n",
       "kawow02                     -0.113384  0.080034  -0.019352    -0.132999   \n",
       "killnik420                  -0.007440 -0.067898  -0.098620     0.100780   \n",
       "melissastandard              0.526253 -0.001568  -0.054477     0.305741   \n",
       "momomeomo                    0.061296  0.224411  -0.016933    -0.156435   \n",
       "myKidsLike2Scream            0.187881 -0.192916   0.342550     0.331572   \n",
       "nankerjphelge               -0.232821  0.098711  -0.145496    -0.273925   \n",
       "nowake                      -0.164002  0.037379  -0.257787    -0.213901   \n",
       "rxvf                         0.005790  0.000110  -0.045580     0.043311   \n",
       "schpork                     -0.174374  0.225523   0.038420    -0.221665   \n",
       "shelbyamonkeysuncle          0.284123 -0.021010   0.202933     0.071585   \n",
       "stuntman628                  0.000803 -0.157453  -0.134214    -0.172822   \n",
       "temporallock                 0.014734 -0.008797  -0.104839    -0.007403   \n",
       "truballa030                 -0.079236 -0.139037  -0.021488    -0.018523   \n",
       "wahmeiman1975                0.001023 -0.027247  -0.012707    -0.179553   \n",
       "\n",
       "                      killnik420  NoYeezyInYourSerrano    ...     glackbuy99  \\\n",
       "AevnNoram              -0.235987             -0.145421    ...      -0.121178   \n",
       "Ashaman21               0.207720              0.039399    ...      -0.067171   \n",
       "Colin03129             -0.036224              0.068391    ...      -0.022279   \n",
       "DankDungeonDelver       0.032233             -0.224168    ...      -0.010482   \n",
       "DuckyDawg55             0.025110             -0.125271    ...      -0.008995   \n",
       "EmmettRapaportNBA      -0.263069              0.102228    ...       0.053561   \n",
       "Flashy_Gardener         0.074441             -0.216465    ...       0.058770   \n",
       "Gay_Black_Atheist      -0.057723              0.171161    ...      -0.121293   \n",
       "GuiHarrison             0.243221             -0.061132    ...       0.105808   \n",
       "Jimmy2e                -0.084548              0.079485    ...      -0.127731   \n",
       "Macklebro              -0.113734             -0.025997    ...      -0.086080   \n",
       "NoYeezyInYourSerrano   -0.140875              0.700255    ...      -0.269141   \n",
       "QuoteMasterLT          -0.082692              0.197166    ...      -0.053060   \n",
       "TheOddScientist         0.100255             -0.080974    ...      -0.008235   \n",
       "Yaglis                 -0.012227             -0.020510    ...       0.017563   \n",
       "a_frayn                 0.055001             -0.228811    ...       0.033255   \n",
       "alreadypiecrust         0.099406             -0.171300    ...       0.039163   \n",
       "cocorazor               0.264245             -0.247964    ...       0.128899   \n",
       "ctrl-shft-esc          -0.113258              0.131833    ...      -0.073867   \n",
       "darkhorn               -0.149813              0.001157    ...       0.152390   \n",
       "dntletmygfknowimhere   -0.117018              0.200928    ...       0.011562   \n",
       "dvaldez0919             0.011387             -0.012898    ...      -0.009932   \n",
       "glackbuy99              0.130217             -0.162031    ...       0.729558   \n",
       "iamnotkobe             -0.122078              0.009485    ...      -0.074374   \n",
       "jessetmia              -0.032400             -0.071126    ...      -0.052440   \n",
       "jl_theprofessor         0.057460             -0.042503    ...      -0.051552   \n",
       "jlawler                 0.218810             -0.141652    ...      -0.035685   \n",
       "kawow02                -0.193383              0.162424    ...       0.077242   \n",
       "killnik420              0.756032             -0.193047    ...       0.050804   \n",
       "melissastandard        -0.040500             -0.121763    ...      -0.010509   \n",
       "momomeomo              -0.090280             -0.010445    ...       0.128589   \n",
       "myKidsLike2Scream       0.067981              0.053068    ...      -0.081328   \n",
       "nankerjphelge          -0.043649              0.014998    ...       0.091833   \n",
       "nowake                 -0.020927             -0.026746    ...      -0.223722   \n",
       "rxvf                    0.205412             -0.033282    ...       0.037195   \n",
       "schpork                -0.314490              0.180524    ...      -0.084265   \n",
       "shelbyamonkeysuncle    -0.126287             -0.057307    ...      -0.074570   \n",
       "stuntman628             0.031818              0.019503    ...      -0.002295   \n",
       "temporallock            0.227603             -0.049385    ...      -0.036115   \n",
       "truballa030            -0.036392             -0.136352    ...       0.075229   \n",
       "wahmeiman1975           0.041747             -0.125105    ...      -0.086699   \n",
       "\n",
       "                      AevnNoram  wahmeiman1975  Flashy_Gardener  \\\n",
       "AevnNoram              0.695392      -0.015190        -0.079269   \n",
       "Ashaman21             -0.174363       0.121517        -0.070957   \n",
       "Colin03129            -0.125436       0.114725         0.000715   \n",
       "DankDungeonDelver      0.029036      -0.111219         0.145534   \n",
       "DuckyDawg55           -0.004239      -0.140664        -0.069674   \n",
       "EmmettRapaportNBA      0.001222       0.315398         0.012474   \n",
       "Flashy_Gardener        0.056927       0.314691         0.882818   \n",
       "Gay_Black_Atheist      0.130341       0.097593        -0.190223   \n",
       "GuiHarrison            0.066518      -0.185273        -0.050678   \n",
       "Jimmy2e                0.001857       0.090390        -0.029601   \n",
       "Macklebro             -0.141624      -0.044117        -0.194757   \n",
       "NoYeezyInYourSerrano  -0.035682      -0.045300        -0.251411   \n",
       "QuoteMasterLT         -0.172455      -0.245305        -0.157970   \n",
       "TheOddScientist        0.255954       0.162383         0.279963   \n",
       "Yaglis                 0.004730      -0.130201        -0.117998   \n",
       "a_frayn                0.180035       0.124823         0.322245   \n",
       "alreadypiecrust        0.131350      -0.125048         0.153761   \n",
       "cocorazor             -0.074666      -0.094271         0.267266   \n",
       "ctrl-shft-esc          0.128621      -0.187376        -0.059074   \n",
       "darkhorn              -0.034922       0.076691         0.022692   \n",
       "dntletmygfknowimhere  -0.132123      -0.139535        -0.127791   \n",
       "dvaldez0919           -0.000082       0.038820        -0.011000   \n",
       "glackbuy99            -0.031905       0.035657         0.225458   \n",
       "iamnotkobe             0.128434       0.121621        -0.117408   \n",
       "jessetmia             -0.055401      -0.005007         0.088114   \n",
       "jl_theprofessor        0.258640       0.064370         0.098959   \n",
       "jlawler                0.024926       0.037276         0.079672   \n",
       "kawow02               -0.243455      -0.106422        -0.182656   \n",
       "killnik420            -0.171420       0.066287         0.157928   \n",
       "melissastandard        0.012672      -0.134081         0.176694   \n",
       "momomeomo             -0.058027      -0.210535        -0.064389   \n",
       "myKidsLike2Scream     -0.139310      -0.153102        -0.128235   \n",
       "nankerjphelge         -0.024409      -0.051255        -0.131542   \n",
       "nowake                 0.332059       0.081698        -0.014706   \n",
       "rxvf                  -0.020297      -0.163396        -0.023521   \n",
       "schpork                0.014050       0.292551         0.117048   \n",
       "shelbyamonkeysuncle   -0.120388      -0.262329        -0.104864   \n",
       "stuntman628            0.016155       0.035013         0.072333   \n",
       "temporallock          -0.013848      -0.103905        -0.197424   \n",
       "truballa030            0.045389      -0.032224        -0.238744   \n",
       "wahmeiman1975         -0.026418       0.741068         0.255066   \n",
       "\n",
       "                      Gay_Black_Atheist   kawow02  dvaldez0919  cocorazor  \\\n",
       "AevnNoram                      0.007729 -0.100473    -0.147875  -0.109408   \n",
       "Ashaman21                      0.163876  0.010027     0.013240   0.002931   \n",
       "Colin03129                    -0.059132  0.308662    -0.071668  -0.110783   \n",
       "DankDungeonDelver             -0.050935 -0.015748    -0.121626   0.049232   \n",
       "DuckyDawg55                    0.025607 -0.189279     0.138388   0.206339   \n",
       "EmmettRapaportNBA              0.212947  0.193072    -0.064351  -0.243341   \n",
       "Flashy_Gardener               -0.153332 -0.009024    -0.035538   0.247204   \n",
       "Gay_Black_Atheist              0.673280  0.127645    -0.019016  -0.146930   \n",
       "GuiHarrison                   -0.004974 -0.035610    -0.231362  -0.010895   \n",
       "Jimmy2e                       -0.263151  0.127507    -0.221698  -0.026097   \n",
       "Macklebro                      0.114629 -0.027176     0.271543  -0.037908   \n",
       "NoYeezyInYourSerrano          -0.001170  0.165660     0.000990  -0.377418   \n",
       "QuoteMasterLT                 -0.077724 -0.074487     0.276626   0.085900   \n",
       "TheOddScientist               -0.078121 -0.187504    -0.070349   0.135806   \n",
       "Yaglis                         0.197414  0.170174    -0.081575   0.051243   \n",
       "a_frayn                       -0.051787 -0.196968    -0.136615   0.162711   \n",
       "alreadypiecrust               -0.140030 -0.133713    -0.230443   0.189331   \n",
       "cocorazor                     -0.124575 -0.127994    -0.141446   0.929678   \n",
       "ctrl-shft-esc                 -0.046838 -0.034956    -0.091593   0.127053   \n",
       "darkhorn                       0.144968  0.030359    -0.032091  -0.043569   \n",
       "dntletmygfknowimhere          -0.163170 -0.179837     0.288102   0.025808   \n",
       "dvaldez0919                   -0.078047 -0.319448     0.408319  -0.056353   \n",
       "glackbuy99                     0.027872  0.021430    -0.046336   0.132697   \n",
       "iamnotkobe                     0.075923  0.049937    -0.015333  -0.206761   \n",
       "jessetmia                      0.031725 -0.003489    -0.045015  -0.198497   \n",
       "jl_theprofessor               -0.177422  0.015531    -0.290785  -0.141340   \n",
       "jlawler                       -0.121877 -0.062153     0.042536  -0.112986   \n",
       "kawow02                        0.137997  0.484714    -0.096204  -0.208113   \n",
       "killnik420                    -0.296101 -0.270563    -0.013725   0.349071   \n",
       "melissastandard               -0.144185 -0.205156     0.088444   0.145595   \n",
       "momomeomo                     -0.054840  0.134454    -0.113650   0.031039   \n",
       "myKidsLike2Scream             -0.034137 -0.126741     0.216293   0.089858   \n",
       "nankerjphelge                 -0.083429  0.280201    -0.361619  -0.072495   \n",
       "nowake                         0.074051  0.029988    -0.109253  -0.159097   \n",
       "rxvf                          -0.072948  0.065204    -0.079752   0.057269   \n",
       "schpork                        0.135327  0.384155    -0.014700  -0.340663   \n",
       "shelbyamonkeysuncle           -0.083788 -0.074173     0.126785   0.166051   \n",
       "stuntman628                   -0.055356 -0.172221     0.035153  -0.111129   \n",
       "temporallock                  -0.132981 -0.059080    -0.076430  -0.054260   \n",
       "truballa030                    0.090999 -0.032677     0.049403  -0.180130   \n",
       "wahmeiman1975                  0.077713 -0.101227     0.137010  -0.006540   \n",
       "\n",
       "                      jessetmia   Jimmy2e  \n",
       "AevnNoram             -0.093517  0.020842  \n",
       "Ashaman21              0.129620  0.032462  \n",
       "Colin03129             0.084536  0.384408  \n",
       "DankDungeonDelver      0.258758 -0.009962  \n",
       "DuckyDawg55           -0.026809 -0.151351  \n",
       "EmmettRapaportNBA      0.032843  0.145931  \n",
       "Flashy_Gardener        0.139687 -0.014765  \n",
       "Gay_Black_Atheist      0.013438 -0.098373  \n",
       "GuiHarrison           -0.017911 -0.053957  \n",
       "Jimmy2e                0.071015  0.594095  \n",
       "Macklebro             -0.278673 -0.208811  \n",
       "NoYeezyInYourSerrano  -0.081972  0.258674  \n",
       "QuoteMasterLT         -0.295402 -0.178466  \n",
       "TheOddScientist        0.132196  0.257111  \n",
       "Yaglis                -0.112815  0.033900  \n",
       "a_frayn                0.265456 -0.065834  \n",
       "alreadypiecrust       -0.119407  0.015312  \n",
       "cocorazor             -0.169047 -0.113545  \n",
       "ctrl-shft-esc         -0.104845 -0.181873  \n",
       "darkhorn              -0.174443  0.198721  \n",
       "dntletmygfknowimhere  -0.182127 -0.253359  \n",
       "dvaldez0919            0.146944 -0.186908  \n",
       "glackbuy99            -0.081239 -0.050172  \n",
       "iamnotkobe             0.019344 -0.047522  \n",
       "jessetmia              0.690508  0.150497  \n",
       "jl_theprofessor        0.224897  0.297260  \n",
       "jlawler                0.248659  0.094596  \n",
       "kawow02               -0.100974  0.243820  \n",
       "killnik420             0.113506 -0.008599  \n",
       "melissastandard       -0.193471 -0.241437  \n",
       "momomeomo             -0.154052 -0.070656  \n",
       "myKidsLike2Scream     -0.155167 -0.235659  \n",
       "nankerjphelge         -0.155376  0.332087  \n",
       "nowake                 0.323395  0.305168  \n",
       "rxvf                  -0.039305 -0.043001  \n",
       "schpork                0.077938  0.135477  \n",
       "shelbyamonkeysuncle   -0.255116 -0.211261  \n",
       "stuntman628            0.036916 -0.058539  \n",
       "temporallock           0.124882 -0.054173  \n",
       "truballa030            0.002647 -0.259369  \n",
       "wahmeiman1975          0.272525  0.094750  \n",
       "\n",
       "[41 rows x 41 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pdf.values[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_matches = pdf.values[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 20., 102., 341., 453., 366., 233.,  90.,  26.,   7.,   2.]),\n",
       " array([-0.41638809, -0.31301256, -0.20963703, -0.10626149, -0.00288596,\n",
       "         0.10048957,  0.2038651 ,  0.30724063,  0.41061616,  0.51399169,\n",
       "         0.61736723]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(matches)\n",
    "plt.hist(non_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_json('sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_mas = non_matches.reshape(41,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_mas_max = np.max(non_mas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9512195121951219"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(matches > non_mas_max) / len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
